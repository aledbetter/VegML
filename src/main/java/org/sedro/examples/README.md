# VegML Examples

Intro.. TODO

Each example is a stand-alone application with a main method and no exernal dependencies aside from data and VegML.


## DataSets
The datasets used for these examples are available at the following locations:
 - [Rotten Tomatoes](https://www.cs.cornell.edu/people/pabo/movie-review-data/)
 - [Brown Corpus](https://www.kaggle.com/nltkdata/brown-corpus)
 - [ConLL 2017 Shared Task - multi-language corpus](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1989)
 - [WSJ Treebank3 Corpus; not free](https://catalog.ldc.upenn.edu/LDC2000T43)
 
## Running Examples
Some of the examples require memory beyond the default limit of VM add to the command line: -Xms2g -Xmx128g


## Test Models
**VegTestModels**

	Utility to test a trained saved model or set of models with one of the datasets.
	Some configuration is available from the command line.
	
	General usecase is to test all models in a directory or all with a given filename prefix

## Part-of-Speech tagging
**GenPosViaText**

	 Part of speech tagging via text (produces models as per the RPM paper)
	 
	 Train and Test based on token text input
	 <text1> <text2> <text-f> <text4> <text5>
	 
	 Text is simply tokenized and fed in with the tags, in some datasets multiple tags may be trained to the same frame (WSJTreebank3)
	 
	 To see the results run VegTestModels with the directory set to ../models

**GenPosViaMix**

	 Part of speech tagging via mixed text (produces models as per the RPM paper)
	  
	 Train and Test based on mixed token input
	 <r-pos> <r-pos> <text> <p-pos> <p-pos>
	 
	 Were r-pos are results from predictions on prior frames and p-pos are predictions on future frames based
	 on another model; either affix/pos or text/pos
	
	 To see the results run VegTestModels with the directory set to ../models

**GenPosViaAffix**

	 Part of speech tagging via characters (produces models as per the RPM paper)
	 
	 Train and Test based on characters in the text and a string format
	 <s1> <s2> <s3> <e3> <e2> <e1> <format>
	 
	 Where the characters from the start are set to start of frame for prefix size
	 and characters from the end are set to the end of frame for suffix size
	 
	 This is not very affective for languages that do not have prefixes/suffixes or formats that imply semantics
	
	 To see the results run VegTestModels with the directory set to ../models

**TestPosViaTextFmt**

	 Part of speech tagging via text/format dependent variable
	 
	 Train and Test based on token text input and format
	 <text1> <text2> <text-f> <text4> <text5>
	 <fmt>   <fmt>   <fmt>    <fmt>   <fmt>
	 
	 Text is simply tokenized and fed in with the tags, in some datasets multiple tags may be rained to the same frame (WSJTreebank3)
	  
	 This utilizes the dependent associated data variables, thus the input frame is a matrix
	 Currently the dependent variable sets are experimental (not complete)
 
 **GenPosViaMerged**
 
	 Part of speech tagging generated by merging models from GenPosViaAffix/GenPosViaText/GenPosViaMix
	 the base models must be generated by running GenPosViaAffix/GenPosViaText/GenPosViaMix prior to running this command
	 all the models are located in ../models
	 
	 To see the results run VegTestModels with the directory set to ../models

 **testModelUsePOS**
	
	Use models generated from TestPosViaText to show how to frame data, get predictions, 
	view prediction source information, export as a solid model or as JSON
	
	 
## Movie Review Sentiment
**SentimentRTomato**

	 Boolean Sentiment for movie reviews - Rotten Tomatoes
	 
	 Train model with 70% of the data. Training is as segments that is each review is a segment has has a single value 
	 trained to it. Prediction follows the same, thus the Segment APIs are used in VegML.
	 
	 Data pre-processing: tokenized, lowercase, start and end of file marked

## Language Model
**NGramLanguageModel**

	 Language Model: Simple N-Grams 
	 
	 With VegML an N-Gram is represented by a single NumberSet 3-Gram: x x x -> v
	 So a more practical simple N-Gram for this example would be the 1 - 8 Grams
	 - where each can provide its own result of next or the standard results can be used to smooth the value

## Linear Motion
**LinearMove**

	 Test move from integer start to integer goal then stop. both points are selected randomly.
	 This is a very simple test of training model for controlling linear motion. A few modifications a
	 re added to allow positive and negative training.

## Learning Curve for dataset
**MapLearningCurve**

	 Map the learning curve of RPM
	 
	 For this test WSJ treebank3 is used (can change) and model is trained and tested for Part of Speech tagging
	 
	 The process:
	  - until all tokens trained
	   	- train N number of tokens from training set
	   	- test full test data set and get correct count, save data point for graph
	 
	 exports as a csv file to load and graph
	 
	 This could be extended to tune the data for each cycle as well, this would improve accuracy and MAY learn faster

## Symbolic Rule Export
**SymbolicRulesExport**

	 Export rules from a trained model. 
	 The rules are symbolic and yield probabilities, for any information any number of rules may match.
	 To get the best result the all the matching rules will need to be summed.
	 
	 The model in this case is trained with Brown Corps for Part of speech tagging

## Adaptive Training
**AdaptiveTraining**

	 TODO: not yet documented or explained
	
	 Example use of Adaptive training to create a complex mixed model
	  
	 Adaptive training allows the correct relationships and numberSets to be automatically assessed as information
	 is added to the model. This reduces human errors and judgment from the process and produces smaller, faster, and better models.
	  
	 It is not documented anywhere at this time: TODO
	 
	 Again this is part of speech tagging used to demonstrate the methodology and software feature that implements it

## Command Line
**VegCmdLine**

	The command line tool is currently out of date and in serious need of rework.

